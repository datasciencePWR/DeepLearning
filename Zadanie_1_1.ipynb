{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wielowarstwowa sieć jednokierunkowa MLP w Tensorflow, Część I\n",
    "\n",
    "## Wstęp:\n",
    "\n",
    "Celem ćwiczenia jest wprowadzenie do biblioteki Tensorflow i  przypomnienie podstawowej sieci MLP i wpływu hiperparametrów na uczenie i jakość otrzymywanych wyników.\n",
    "Sieć powinna rozwiązywać problem klasyfikacji obrazów ze zbioru  CIFAR-10.  \n",
    "Należy zdefiniować architekturę modelu, funkcję celu i dostarczyć dane do sieci. (Tensorflow automatycznie oblicza pochodne funkcji celu).\n",
    "\n",
    "\n",
    "Zadania na laboratorium będą oparte o interfejs Subclassing API. W notebooku znajduje się treść zadania wraz ze zdefiniowanymi klasami bazowymi i narzędziami pomocniczymi.\n",
    "\n",
    "Paczki, które mogą być dodatkowo zastosowane:  \n",
    "- numpy  \n",
    "- scikit-learn (Metryki)  \n",
    "- matplotlib, seaborn (Wykresy)  \n",
    "- tqdm (Pasek postępu)\n",
    "\n",
    "\n",
    "## Lista zadań (Część I): \n",
    "1. Wykorzystując klasę bazową zdefiniowaną w BaseLayer zaimplementuj warstwę w pełni połączoną. (Dodawanie zmiennych do warstwy odbywa się za pomocą metody add_weight). Źródło:  https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) (0.5 pkt).\n",
    "\n",
    "2. Wykorzystując klasę bazową zdefiniowaną w BaseModel i zaimplementowaną warstwę w pełni połączoną w zadaniu 1 zdefiniuj architekturę sieci, funkcję uczenia sieci i funkcję ewaluacji (0.5 pkt).  \n",
    "    **Przetwarzanie wstępne**\n",
    "    - Spłaszczenie obrazu z wymiaru 32x32x3 na wymiar 3072\n",
    "    \n",
    "   **Architektura modelu do implementacji**\n",
    "    - Warstwa w pełni połączona z 128 neuronami i funkcją aktywacji ReLU\n",
    "    - Warstwa w pełni połączona z 10 neuronami i funkcją aktywacji Softmax\n",
    "    \n",
    "    Funkcje aktywacji znajdują się w module tensorflow.keras.activation\n",
    "    \n",
    "   **Hiperparametry uczenia**\n",
    "    - Wielkość paczki: 100\n",
    "    - Optymalizator: Adam\n",
    "    - Współczynnik uczenia: 0.01\n",
    "    - Liczba epok: 10\n",
    "    - Funkcja kosztu: tf.keras.losses.SparseCategoricalCrossentropy\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "3. Przedstaw wykres accuracy, krzywą funkcji kosztu i podaj macierz pomyłek (confusion matrix) (1 pkt)\n",
    "4. Zwizualizuj kilka przykładów na klasę, dla których model podejmowal złą decyzję i przeanalizuj dlaczego (1 pkt)\n",
    "\n",
    "Jakość analizy i realizacji (prawidłowość wniosków, klarowność prezentacji, rozumienie modelu, jakość kodu)  (2 pkt)  \n",
    "\n",
    "### Ograniczenia\n",
    "\n",
    "1. Zadania 1 i 2 muszą być oddane razem z Zadaniem 3\n",
    "\n",
    "2. Wykorzystanie gotowych modułów implementujących warstwy sieci np. tensorflow.keras.layers i innych jest zabronione!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "\n",
    "### Wcztywanie zbioru danych i mechanizm paczkowania danych\n",
    "\n",
    "Zbiór CIFAR10 jest jednym ze zbiorów danych, dla których zdefiniowano interfejs do jego wczytywania w module `tensorflow.keras.datasets`. \n",
    "\n",
    "Wczytanie zbiorów wygląda następująco\n",
    "```python\n",
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.cifar10.load_data()\n",
    "```\n",
    "\n",
    "Normalizacja wartości piskeli 0-255 do 1\n",
    "\n",
    "```python\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "```\n",
    "\n",
    "### Paczkowanie danych \n",
    "Do iterowania zbioru danych i podzielenia na paczki (ang. batch) można wykorzystać interfejs zdefiniowany w `tensorflow.data.Dataset`\n",
    "\n",
    "Przykładowy kod:\n",
    "```python\n",
    "# Utworzenie obiektu\n",
    "train_dataset = tensorflow.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle i zdefiniowanie rozmiaru paczki\n",
    "# buffer_size - rozmiar bufora do przeprowadzenia operacji shuffle (Ważne!); \n",
    "# batch_size - rozmiar paczki;\n",
    "train_dataset = train_dataset.shuffle(buffer_size=50000).batch(batch_size=100)\n",
    "\n",
    "# Iterowanie po paczkach:\n",
    "for x, y in train_dataset:\n",
    "    Some code...\n",
    "```\n",
    "\n",
    "**Rozmiar bufora (buffer_size) wpływa na losowość całej operacji shuffle!**   \n",
    "Szczegóły można znaleźć tutaj: [LINK](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasy bazowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class AbstractLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Abstract Layer.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inits the class.\"\"\"\n",
    "        super(AbstractLayer, self).__init__()\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Makes forward pass of the layer\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class AbstractModel(tf.keras.Model):\n",
    "    \"\"\"Abstract model.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Inits the class.\"\"\"\n",
    "        super(AbstractModel, self).__init__()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"Makes forward pass of the network.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, **kwargs):\n",
    "        \"\"\"Implements learning loop for the model.\n",
    "        \n",
    "        kwargs can contain optional parameters such as \n",
    "        num_epochs, batch_size, etc.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predicts outputs based on inputs (x).\"\"\"\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozwiązanie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
